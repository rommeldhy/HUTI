# dataset config : Sequential Recommendation
USER_ID_FIELD: user_id
ITEM_ID_FIELD: item_id
TIME_FIELD: timestamp
load_col:
    inter: [user_id, item_id, timestamp]
ITEM_LIST_LENGTH_FIELD: item_length
LIST_SUFFIX: _list
MAX_ITEM_LIST_LENGTH: 50

user_inter_num_interval: "[5,inf)"
item_inter_num_interval: "[5,inf)"

# model config
k_interests: 5
n_layers: 2                     # (int) The number of transformer layers in transformer encoder.
n_heads: 2                      # (int) The number of attention heads for multi-head attention layer.
hidden_size: 64                 # (int) The input and output hidden size.
inner_size: 256                 # (int) The imensionality in feed-forward layer.
hidden_dropout_prob: 0.5        # (float) The probability of an element to be zeroed.
attn_dropout_prob: 0.5          # (float) The probability of an attention score to be zeroed.
hidden_act: 'gelu'              # (str) The activation function in feed-forward layer.
layer_norm_eps: 1e-12           # (float) The value added to the denominator for numerical stability.
initializer_range: 0.02         # (float) The range of weights initialization.
loss_type: 'CE'                 # (str) The type of loss function.

# Training and evaluation config
epochs: 500
train_batch_size: 1024
eval_batch_size: 8
train_neg_sample_args: ~
eval_args:
    group_by: user
    order: TO
    split: {'LS': 'valid_and_test'}
    mode: full
metrics: ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']
topk: [1, 5, 10, 20, 50]
valid_metric: MRR@10
metric_decimal_place: 4

# Env
gpu_id: '3'
show_progress: False
save_dataloaders: 'saved/'
save_dataset: True